# Import necessary libraries
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.inspection import permutation_importance
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error, roc_auc_score, roc_curve, auc, confusion_matrix
from sklearn.metrics import cohen_kappa_score
from statsmodels.stats.outliers_influence import variance_inflation_factor
from sklearn.feature_selection import mutual_info_classif

# Load the dataset
data = pd.read_csv("C:\\Users\\LE\\Downloads\\THESIS\\Program\\CSV\\GRID_LABEL_KTMBASIN_classify_v2.2.csv")

# Calculate correlation of the dataset
correlation_matrix = data.corr()
print("Correlation Matrix:")
print(correlation_matrix)

# Draw heatmap for correlation matrix
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='Blues')
#plt.imshow(correlation_matrix, interpolation='nearest')
plt.title("Correlation Matrix")
#plt.colorbar()
tick_marks = [i for i in range(len(data.columns))]
plt.xticks(tick_marks, data.columns, rotation=45)
plt.yticks(tick_marks, data.columns)
plt.tight_layout()
plt.show()

# Preprocess the data
# Split the data into training and testing sets
X = data[["near_dis", "sediment_thick", "predom", "vs30", "pga", "geo_form"]]
y = data["LIQ"]

TEST_SIZE = 0.3
RANDOM_STATE = 36

# Get hyperparameters from user
# kernel = ['linear', 'poly', rbf', sigmoid']
# C = [0.001, 0.01, 0.1, 1, 10, 100]
# gamma = [0.001, 0.01, 0.1, 1, 10, 100, 'auto']
# degree = [2, 3, 4, 5]
# probability = ['True', 'False']

kernel = 'linear'
C = 225
gamma = 'scale'
degree = 1
probability = bool('True')

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = TEST_SIZE, random_state = RANDOM_STATE)

# Calculate VIF
vif = pd.DataFrame()
vif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]
vif['features'] = X_train.columns
print("Variance Inflation Factor (VIF):")
print(vif)

# Calculate feature importance using Information Gain Ratio
information_gain_ratio = mutual_info_classif(X_train, y_train)
print("Feature Importance (Information Gain Ratio):")
for i, importance in enumerate(information_gain_ratio):
    print(f"Feature {i+1}: {X.columns[i]} (importance: {importance:.3f})")

# Draw bar chart for feature importance using Information Gain Ratio
plt.figure(figsize=(10, 6))
plt.bar(range(len(information_gain_ratio)), information_gain_ratio, align="center")
plt.xticks(range(len(information_gain_ratio)), [{X.columns[i]} for i in range(len(information_gain_ratio))])
plt.xlabel("Variables")
plt.ylabel("Importance")
plt.title("Feature Importance (Information Gain Ratio)")
for i,v in enumerate(information_gain_ratio):
    plt.text(i,v+0.01,f"{v:.3f}", ha="center", weight="bold")
plt.show()

# Create SVM model
if kernel == "poly":
    svm_model = SVC(kernel=kernel, C=C, degree=degree, probability=probability)
elif kernel == "rbf":
    svm_model = SVC(kernel=kernel, C=C, gamma=gamma, probability=probability)
else:
    svm_model = SVC(kernel=kernel, C=C, probability=probability)

# Train the SVM model
svm_model.fit(X_train, y_train)

# Make predictions
y_pred = svm_model.predict(X_test)
y_pred_proba_test = svm_model.predict_proba(X_test)[:, 1]

## MODEL EVALUATION
# For accuracy
accuracy = accuracy_score(y_test, y_pred)
# For regression
mse = mean_squared_error(y_test, y_pred)
# For precision
precision = precision_score(y_test, y_pred)
# For recall
recall = recall_score(y_test, y_pred)
# For f1 score
f1 = f1_score(y_test, y_pred)

# For AUC score
auc_score = roc_auc_score(y_test, y_pred_proba_test)
auc_error = 1 - auc_score

# For Cohen-Kappa Score
kappa = cohen_kappa_score(y_test, y_pred)

print(f"Accuracy: {accuracy:.3f}")
print(f"Precision: {precision:.3f}")
print(f"Recall: {recall:.3f}")
print(f"F1 score: {f1:.3f}")
print(f"Mean Squared Root: {mse:.3f}")
print(f"AUC score: {auc_score:.3f}")
print(f"AUC error: {auc_error:.3f}")
print(f"Cohen Kappa Score: {kappa:.3f}")

# Calculate confusion matrix
conf_mat = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(conf_mat)

# Calculate true positive rate, false positive rate, true negative rate, false negative rate
tn, fp, fn, tp = conf_mat.ravel()
tpr = tp / (tp + fn)  # True positive rate
fpr = fp / (fp + tn)  # False positive rate
tnr = tn / (tn + fp)  # True negative rate
fnr = fn / (fn + tp)  # False negative rate

print(f"True Positive Rate: {tpr:.3f}")
print(f"False Positive Rate: {fpr:.3f}")
print(f"True Negative Rate: {tnr:.3f}")
print(f"False Negative Rate: {fnr:.3f}")

# Plot confusion matrix as a heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(conf_mat, annot=True, cmap='Blues', fmt = '.0f')
#plt.imshow(conf_mat, interpolation='nearest')
plt.title("Confusion Matrix")
#plt.colorbar()
tick_marks = [i for i in range(2)]
plt.xticks(tick_marks, ["Non-liquefiable", "Liquefiable"], rotation=0)
plt.yticks(tick_marks, ["Non-liquefiable", "Liquefiable"])
plt.tight_layout()
plt.show()

# Compute permutation importance
result = permutation_importance(svm_model, X_test, y_test, n_repeats=10, random_state=RANDOM_STATE)

# Compute AUROC curve for test data
fpr_test, tpr_test, _ = roc_curve(y_test, y_pred_proba_test)
roc_auc_test = auc(fpr_test, tpr_test)

# Compute AUROC curve for train data
y_pred_proba_train = svm_model.predict_proba(X_train)[:, 1]
fpr_train, tpr_train, _ = roc_curve(y_train, y_pred_proba_train)
roc_auc_train = auc(fpr_train, tpr_train)

# Plot AUROC curve for both test and train data
plt.figure()
plt.plot(fpr_test, tpr_test, color='darkorange', lw=2, label='Test ROC curve (area = %0.2f)' % roc_auc_test)
plt.plot(fpr_train, tpr_train, color='green', lw=2, label='Train ROC curve (area = %0.2f)' % roc_auc_train)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

### Exporting prediciton to shapefile

import geopandas as gpd
import numpy as np
import pandas as pd

# Read the shapefile
gdf = gpd.read_file(r'D:\\ARC GIS\\KTM VALLEY\\WGS_1984_UTM_ZONE_45N\\GRID\\GRID_LABEL_KTMBASIN_Classify_v2.2.shp')

# Repeat the predictions to match the number of features
y_pred_repeated = np.repeat(y_pred_proba_test, len(gdf) // len(y_pred_proba_test) + 1)[:len(gdf)]

# Create a new DataFrame with the repeated predictions
df = pd.DataFrame(y_pred_repeated, columns=['LSM'])

# Reset the index of the GeoDataFrame to create a unique index
gdf.reset_index(drop=True, inplace=True)

# Assign the repeated predictions to a new column in the GeoDataFrame
gdf['LSM'] = df['LSM']

# Set the CRS
gdf.set_crs(epsg=32645, inplace=True)

# Save the GeoDataFrame to a new shapefile
gdf.to_file(r'D:\\ARC GIS\\KTM VALLEY\\WGS_1984_UTM_ZONE_45N\\METHOD 2\\Classify_v2.2\\method2_grid_1_0.3_36_SVM_CLassify_v2.2.shp')
