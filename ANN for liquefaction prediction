import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error, roc_auc_score, roc_curve, auc, confusion_matrix
from sklearn.metrics import cohen_kappa_score
from statsmodels.stats.outliers_influence import variance_inflation_factor
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_selection import mutual_info_classif

# Set a random seed for reproducibility
torch.manual_seed(36)
np.random.seed(36)

# Load the dataset
data = pd.read_csv("C:\\Users\\LE\\Downloads\\THESIS\\Program\\CSV\\GRID_LABEL_KTMBASIN_classify_v2.2.csv")

# Calculate correlation of the dataset
correlation_matrix = data.corr()
print("Correlation Matrix:")
print(correlation_matrix)

# Draw heatmap for correlation matrix
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='Blues')
#plt.imshow(correlation_matrix, interpolation='nearest')
plt.title("Correlation Matrix")
#plt.colorbar()
tick_marks = [i for i in range(len(data.columns))]
plt.xticks(tick_marks, data.columns, rotation=45)
plt.yticks(tick_marks, data.columns)
plt.tight_layout()
plt.show()

# Preprocess the data
X = data[["near_dis", "sediment_thick", "predom", "vs30", "pga", "geo_form"]]
y = data["LIQ"]

# Calculate VIF
vif = pd.DataFrame()
vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]
vif['features'] = X.columns
print("Variance Inflation Factor (VIF):")
print(vif)

# Create a custom dataset class
class LiquefactionDataset(Dataset):
    def __init__(self, X, y):
        self.X = X
        self.y = y

    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        x = self.X.iloc[idx, :].values
        y = self.y.iloc[idx]
        return {
            'x': torch.tensor(x, dtype=torch.float),
            'y': torch.tensor(y, dtype=torch.long)
        }

# Create data loaders

max_depth = 10  # maximum depth of the decision tree
n_estimators = 100  # number of decision trees in the ensemble
random_state = 36  # random state for reproducibility
test_size = 0.3  # test size for testing data

# Hyperparameters
hidden_size = 64
learning_rate = 0.0001
epochs = 300
batch_size = 64

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state) 
 
dataset_train = LiquefactionDataset(X_train, y_train) 
dataset_test = LiquefactionDataset(X_test, y_test)
 
train_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, drop_last=False)
test_loader = DataLoader(dataset_test, batch_size=batch_size, shuffle=False, drop_last=False)

# Define the ANN model
class ANNModel(nn.Module):
    def __init__(self, hidden_size):
        super(ANNModel, self).__init__()
        self.fc1 = nn.Linear(6, hidden_size)  # input layer (6) -> hidden layer (128)
        self.fc2 = nn.Linear(hidden_size, hidden_size//2)  # hidden layer (128) -> hidden layer (64)
        self.fc3 = nn.Linear(hidden_size//2, 2)  # hidden layer (64) -> output layer (2)

    def forward(self, x):
        batch_size = x.size(0)  # get the batch size
        x = x.view(batch_size, 6)  # reshape the input tensor
        x = torch.relu(self.fc1(x))  # activation function for hidden layer
        x = torch.relu(self.fc2(x))
        x = self.fc3(x)
        return x
    
model = ANNModel(hidden_size)

# Define the loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

# Calculate feature importance using Information Gain Ratio
information_gain_ratio = mutual_info_classif(X_train, y_train)
print("Feature Importance (Information Gain Ratio):")
for i, importance in enumerate(information_gain_ratio):
    print(f"Feature {i+1}: {X.columns[i]} (importance: {importance:.3f})")

# Draw bar chart for feature importance using Information Gain Ratio
plt.figure(figsize=(10, 6))
plt.bar(range(len(information_gain_ratio)), information_gain_ratio, align="center")
plt.xticks(range(len(information_gain_ratio)), [{X.columns[i]} for i in range(len(information_gain_ratio))])
plt.xlabel("Variables")
plt.ylabel("Importance")
plt.title("Feature Importance (Information Gain Ratio)")
for i,v in enumerate(information_gain_ratio):
    plt.text(i,v+0.01,f"{v:.3f}", ha="center", weight="bold")
plt.show()


# Train the model

for epoch in range(epochs):  # loop over the dataset multiple times
    running_loss = 0.0
    for i, batch in enumerate(train_loader):
        inputs, labels = batch['x'], batch['y']
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
    print(f'Epoch {epoch+1}, Loss: {running_loss / i:.3f}')

# Evaluate the model
model.eval()
test_loss = 0
correct = 0
y_pred_probs = []
y_true = []
with torch.no_grad():
    for batch in test_loader:
        inputs, labels = batch['x'], batch['y']
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        test_loss += loss.item()
        _, predicted = torch.max(outputs, 1)
        correct += (predicted == labels).sum().item()
        y_pred_probs.extend(torch.softmax(outputs, dim=1)[:, 1].cpu().numpy())
        y_true.extend(labels.cpu().numpy())

accuracy = correct / len(test_loader.dataset)
print(f'Test Accuracy: {accuracy:.3f}')

# Calculate precision, recall, F1-score
y_pred = np.array(y_pred_probs) >= 0.5
y_true = np.array(y_true)
precision = precision_score(y_true, y_pred)
recall = recall_score(y_true, y_pred)
f1 = f1_score(y_true, y_pred)
print(f'Precision: {precision:.3f}')
print(f'Recall: {recall:.3f}')
print(f'F1-score: {f1:.3f}')

# Calculate AUROC
auroc = roc_auc_score(y_true, y_pred_probs)
print(f'AUROC: {auroc:.3f}')

# Calculate Kappa score
kappa = cohen_kappa_score(y_true, y_pred)
print(f'Cohen Kappa Score: {kappa:.3f}')

# Calculate confusion matrix
conf_mat = torch.zeros(2, 2)
with torch.no_grad():
    for batch in test_loader:
        inputs, labels = batch['x'], batch['y']
        outputs = model(inputs)
        _, predicted = torch.max(outputs, 1)
        for t, p in zip(labels, predicted):
            conf_mat[t, p] += 1

print("Confusion Matrix:")
print(conf_mat)

# Calculate AUROC for test data
y_pred_probs_test = np.array(y_pred_probs)
y_true_test = np.array(y_true)
auroc_test = roc_auc_score(y_true_test, y_pred_probs_test)
fpr_test, tpr_test, _ = roc_curve(y_true_test, y_pred_probs_test)

# Calculate AUROC for train data
y_pred_probs_train = []
y_true_train = []
with torch.no_grad():
    for batch in train_loader:
        inputs, labels = batch['x'], batch['y']
        outputs = model(inputs)
        _, predicted = torch.max(outputs, 1)
        y_pred_probs_train.extend(torch.softmax(outputs, dim=1)[:, 1].cpu().numpy())
        y_true_train.extend(labels.cpu().numpy())

y_pred_probs_train = np.array(y_pred_probs_train)
y_true_train = np.array(y_true_train)
auroc_train = roc_auc_score(y_true_train, y_pred_probs_train)
fpr_train, tpr_train, _ = roc_curve(y_true_train, y_pred_probs_train)

# Plot ROC curve for both test and train data
plt.figure()
plt.plot(fpr_test, tpr_test, color='darkorange', lw=2, label='Test ROC curve (area = %0.2f)' % auroc_test)
plt.plot(fpr_train, tpr_train, color='green', lw=2, label='Train ROC curve (area = %0.2f)' % auroc_train)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# Calculate true positive rate, false positive rate, true negative rate, false negative rate
tn, fp, fn, tp = conf_mat.ravel()
tpr = tp / (tp + fn)  # True positive rate
fpr = fp / (fp + tn)  # False positive rate
tnr= tn / (tn + fp)  # True negative rate
fnr = fn / (fn + tp)  # False negative rate

print(f"True Positive Rate: {tpr:.3f}")
print(f"False Positive Rate: {fpr:.3f}")
print(f"True Negative Rate: {tnr:.3f}")
print(f"False Negative Rate: {fnr:.3f}")

# Plot confusion matrix as a heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(conf_mat, annot=True, cmap='Blues', fmt = '.0f')
#plt.imshow(conf_mat, interpolation='nearest')
plt.title("Confusion Matrix")
#plt.colorbar()
tick_marks = [i for i in range(2)]
plt.xticks(tick_marks, ["Non-liquefiable", "Liquefiable"], rotation=0)
plt.yticks(tick_marks, ["Non-liquefiable", "Liquefiable"])
plt.tight_layout()
plt.show()

### Exporting prediction to shapefile for accurate mapping

import geopandas as gpd
import numpy as np
import rasterio
from rasterio.transform import Affine
import torch

# Read the shapefile
gdf = gpd.read_file(r'D:\\ARC GIS\\KTM VALLEY\\WGS_1984_UTM_ZONE_45N\\GRID\\GRID_LABEL_KTMBASIN_Classify_v2.2.shp')

# Repeat the predictions to match the number of features
pred_SA_repeated = np.repeat(y_pred_probs_test, len(gdf) // len(y_pred_probs_test) + 1)[:len(gdf)]

# Assign the repeated predictions to a new column in the GeoDataFrame
gdf['LSM'] = pred_SA_repeated

# Set the CRS
gdf.set_crs(epsg=32645, inplace=True)

# Save the GeoDataFrame to a new shapefile
gdf.to_file(r'D:\\ARC GIS\\KTM VALLEY\\WGS_1984_UTM_ZONE_45N\\METHOD 2\\Classify_v2.2\\method2_grid_1_0.3_36_ANN_CLassify_v2.2.shp')

# Get the overall bounds of the GeoDataFrame
minx, miny, maxx, maxy = gdf.total_bounds

# Create a raster output file
with rasterio.open(
    r'D:\\ARC GIS\\KTM VALLEY\\WGS_1984_UTM_ZONE_45N\\METHOD 2\\Classify_v2.2\\method2_grid_1_0.3_36_ANN_CLassify_v2.2.tif',
    'w',
    driver='GTiff',
    height=gdf.shape[0],
    width=gdf.shape[1],
    count=1,
    dtype=rasterio.uint8,
    crs=gdf.crs,
    transform=Affine(30, 0, minx, 0, -30, maxy)
) as dst:
    # Write the LSM values to the raster
    dst.write(gdf['LSM'].values.reshape((1, -1)), 1)
